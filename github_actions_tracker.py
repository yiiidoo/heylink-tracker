#!/usr/bin/env python3
"""
GitHub Actions i√ßin Tek Kontrol Scripti
"""

import urllib.request
import urllib.parse
import json
import re
import random
import hashlib
import time
import os
from datetime import datetime
import requests
import ssl
from bs4 import BeautifulSoup

# Selenium imports (GitHub Actions i√ßin)
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager

# Environment variables'dan oku
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "")
TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID", "")

# Global ge√ßmi≈ü (GitHub Actions'ta persist etmez ama basit i√ßin OK)
page_history = {}

# √úcretsiz proxy listesi (g√ºncellenebilir)
PROXY_LIST = [
    {'http': 'http://51.159.115.233:3128', 'https': 'http://51.159.115.233:3128'},
    {'http': 'http://20.205.61.143:3128', 'https': 'http://20.205.61.143:3128'},
    {'http': 'http://103.151.177.106:8080', 'https': 'http://103.151.177.106:8080'},
    {'http': 'http://185.82.99.181:9091', 'https': 'http://185.82.99.181:9091'},
    {'http': 'http://190.97.226.236:999', 'https': 'http://190.97.226.236:999'},
    {'http': 'http://181.78.22.52:999', 'https': 'http://181.78.22.52:999'},
    {'http': 'http://45.70.236.194:999', 'https': 'http://45.70.236.194:999'},
    {'http': 'http://200.105.215.18:33630', 'https': 'http://200.105.215.18:33630'},
    {'http': 'http://190.103.177.131:80', 'https': 'http://190.103.177.131:80'},
    {'http': 'http://181.78.22.150:999', 'https': 'http://181.78.22.150:999'}
]

HEYLINKS = [
    {
        "url": "https://heylink.me/Kopilbeysponsorlar/",
        "name": "Kopilbey Sponsorlar"
    }
]

def send_telegram_message(message):
    """Telegram mesajƒ± g√∂nder"""
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID:
        print("‚ùå Telegram config eksik")
        return

    try:
        url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
        data = {
            'chat_id': TELEGRAM_CHAT_ID,
            'text': message,
            'parse_mode': 'Markdown',
            'disable_web_page_preview': True
        }

        data = urllib.parse.urlencode(data).encode('utf-8')
        req = urllib.request.Request(url, data=data, method='POST')
        with urllib.request.urlopen(req, timeout=10) as response:
            print("‚úÖ Telegram mesajƒ± g√∂nderildi")
    except Exception as e:
        print(f"‚ùå Telegram hatasƒ±: {e}")

def scrape_heylink(url, name):
    """Sayfayƒ± scrape et ve link sƒ±ralamasƒ± deƒüi≈üikliklerini tespit et"""
    try:
        # Bot-kar≈üƒ±tƒ± headers
        user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15'
        ]

        # Heylink i√ßin Cloudflare bypass headers
        if 'heylink' in url.lower():
            headers = {
                'User-Agent': random.choice(user_agents),
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
                'Accept-Language': 'tr-TR,tr;q=0.9,en-US;q=0.8,en;q=0.7',
                'Accept-Encoding': 'gzip, deflate, br',
                'DNT': '1',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
                'Sec-Fetch-Dest': 'document',
                'Sec-Fetch-Mode': 'navigate',
                'Sec-Fetch-Site': 'cross-site',
                'Sec-Fetch-User': '?1',
                'Cache-Control': 'max-age=0',
                'Sec-Ch-Ua': '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
                'Sec-Ch-Ua-Mobile': '?0',
                'Sec-Ch-Ua-Platform': '"Windows"',
                'Referer': 'https://www.google.com/search?q=heylink',
                'CF-RAY': 'dummy-ray-id',
                'CF-Visitor': '{"scheme":"https"}'
            }
            delay = random.uniform(15, 30)  # Heylink i√ßin √ßok uzun delay
        else:
            # Normal siteler i√ßin
            headers = {
                'User-Agent': random.choice(user_agents),
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
                'Accept-Language': 'tr-TR,tr;q=0.9,en-US;q=0.8,en;q=0.7',
                'Accept-Encoding': 'gzip, deflate, br',
                'DNT': '1',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
                'Sec-Fetch-Dest': 'document',
                'Sec-Fetch-Mode': 'navigate',
                'Sec-Fetch-Site': 'none',
                'Sec-Fetch-User': '?1',
                'Cache-Control': 'max-age=0',
                'Sec-Ch-Ua': '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
                'Sec-Ch-Ua-Mobile': '?0',
                'Sec-Ch-Ua-Platform': '"Windows"',
                'Referer': 'https://www.google.com/',
                'Cookie': ''
            }
            delay = random.uniform(3, 7)  # Normal delay

        print(f"‚è≥ {name}: {delay:.1f}s bekleniyor...")
        time.sleep(delay)

        # Request
        req = urllib.request.Request(url, headers=headers)

        # Heylink i√ßin Selenium kullan (eƒüer mevcutsa)
        if 'heylink' in url.lower():
            print(f"ü§ñ {name}: Selenium ile Cloudflare bypass deneniyor...")
            try:
                chrome_options = Options()
                chrome_options.add_argument('--headless')
                chrome_options.add_argument('--no-sandbox')
                chrome_options.add_argument('--disable-dev-shm-usage')
                chrome_options.add_argument('--disable-gpu')
                chrome_options.add_argument('--window-size=1920,1080')
                chrome_options.add_argument(f'--user-agent={random.choice(user_agents)}')

                driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
                driver.get(url)

                # Sayfa y√ºklenene kadar bekle
                time.sleep(5)
                html = driver.page_source
                driver.quit()

                print(f"‚úÖ {name}: Selenium ba≈üarƒ±lƒ±!")

            except Exception as selenium_error:
                print(f"‚ö†Ô∏è {name}: Selenium ba≈üarƒ±sƒ±z ({selenium_error}), proxy ile requests deneniyor...")
                # Selenium ba≈üarƒ±sƒ±z olursa proxy ile requests dene
                try:
                    proxy = random.choice(PROXY_LIST)
                    response = requests.get(url, headers=headers, proxies=proxy, timeout=30)
                    response.raise_for_status()
                    html = response.text
                    print(f"‚úÖ {name}: Proxy ba≈üarƒ±lƒ±!")
                except Exception as proxy_error:
                    print(f"‚ö†Ô∏è {name}: Proxy de ba≈üarƒ±sƒ±z ({proxy_error}), normal y√∂ntem deneniyor...")
                    # Her ≈üey ba≈üarƒ±sƒ±z olursa normal urllib kullan
                    with urllib.request.urlopen(req, timeout=60, context=ssl._create_unverified_context()) as response:
                        html = response.read().decode('utf-8', errors='ignore')
        else:
            # Normal siteler i√ßin urllib kullan
            with urllib.request.urlopen(req, timeout=30, context=ssl._create_unverified_context()) as response:
                html = response.read().decode('utf-8', errors='ignore')
        # Debug: Save HTML to file for inspection
        with open("heylink_content.html", "w", encoding="utf-8") as f:
            f.write(html)
        print("heylink_content.html dosyasƒ±na kaydedildi.")

        def parse_links_from_html(page_html):
            """Heylink sayfasƒ±ndaki sponsor linklerini √ßƒ±kar."""
            parsed_links = []
            soup = BeautifulSoup(page_html, "html.parser")
            cards = soup.select("div.preview-link-item__component a.preview-link-wrapper")
            for idx, card in enumerate(cards, start=1):
                href = card.get("href", "").strip()
                if not href or href.startswith(("javascript:", "mailto:", "#", "tel:")):
                    continue
                name_el = card.select_one(".link-info .name")
                text = name_el.get_text(strip=True) if name_el else card.get_text(strip=True)
                if not text:
                    text = href
                parsed_links.append(
                    {
                        "position": idx,
                        "text": text[:120],
                        "href": href,
                    }
                )
            return parsed_links

        # Linkleri √ßƒ±kar (BeautifulSoup ile √∂ncelikli, regex yedekli)
        links = parse_links_from_html(html)
        link_count = len(links)

        if not links:
            try:
                # T√ºm link tag'larƒ±nƒ± say (yedek)
                link_count = len(re.findall(r'<a[^>]*href[^>]*>.*?</a>', html, re.IGNORECASE | re.DOTALL))
                link_matches = re.findall(r'<a[^>]*href=["\']([^"\']+)["\'][^>]*>([^<]*)</a>', html, re.IGNORECASE | re.DOTALL)

                for i, (href, text) in enumerate(link_matches[:5]):  # Sadece ilk 5
                    if href and not href.startswith(('javascript:', 'mailto:', '#', 'tel:')):
                        clean_text = text.strip()[:120] if text.strip() else href[:120]
                        links.append({
                            'position': i + 1,
                            'text': clean_text,
                            'href': href
                        })

                if not links:
                    for i in range(min(3, link_count)):  # En fazla 3 bo≈ü link
                        links.append({
                            'position': i + 1,
                            'text': f'Link {i+1}',
                            'href': f'#link{i+1}'
                        })
            except Exception as parse_error:
                print(f"‚ö†Ô∏è Link parsing hatasƒ±: {parse_error}")
                link_count = len(links)


        # Link listesinin hash'i
        links_hash = hashlib.md5(str(links).encode('utf-8')).hexdigest()

        result = {
            "success": True,
            "name": name,
            "url": url,
            "links_found": len(links),
            "links": links[:10],
            "links_hash": links_hash,
            "timestamp": datetime.now().isoformat()
        }

        # Ge√ßmi≈ü ile kar≈üƒ±la≈ütƒ±r
        url_key = url
        if url_key in page_history:
            prev_data = page_history[url_key]
            prev_hash = prev_data.get('links_hash', '')

            if links_hash != prev_hash:
                result["ranking_changed"] = True
                result["change_summary"] = "üîÑ Link sƒ±ralamasƒ± deƒüi≈üti"
            else:
                result["ranking_changed"] = False
                result["change_summary"] = "‚úÖ Link sƒ±ralamasƒ± aynƒ±"
        else:
            result["first_check"] = True
            result["change_summary"] = "üÜï ƒ∞lk kontrol - referans kaydedildi"

        # Ge√ßmi≈üi g√ºncelle
        page_history[url_key] = {
            'links': links,
            'links_hash': links_hash,
            'timestamp': result['timestamp']
        }

        return result

    except Exception as e:
        print(f"‚ùå {name}: Hata - {str(e)}")
        return {
            "success": False,
            "name": name,
            "url": url,
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

def main():
    print("ü§ñ GitHub Actions - Heylink Tracker")
    print("üìä Tek kontrol ba≈ülatƒ±lƒ±yor...")
    print("=" * 50)

    # Ba≈ülangƒ±√ß bildirimi
    start_msg = "ü§ñ **GitHub Actions - Kontrol Ba≈ülƒ±yor**\n\n"
    start_msg += f"üìÖ {datetime.now().strftime('%H:%M:%S')}\n"
    start_msg += f"üéØ **Kopilbey Sponsorlar** sayfasƒ± kontrol ediliyor\n\n"
    start_msg += f"üîÑ Her 15 dakikada bir link sƒ±ralamasƒ± kontrol edilecek"

    send_telegram_message(start_msg)

    results = []
    for heylink in HEYLINKS:
        result = scrape_heylink(heylink["url"], heylink["name"])
        results.append(result)

    # Detaylƒ± rapor
    result_msg = f"ü§ñ **GitHub Actions - Kontrol Tamamlandƒ±**\n\n"
    result_msg += f"üìÖ {datetime.now().strftime('%H:%M:%S')}\n\n"

    successful = sum(1 for r in results if r["success"])
    errors = len(results) - successful
    changes_found = 0

    result_msg += f"üìä **Genel Durum:**\n"
    result_msg += f"‚úÖ {successful} ba≈üarƒ±lƒ±\n"
    if errors > 0:
        result_msg += f"‚ùå {errors} hata\n"
    result_msg += "\n"

    for result in results:
        result_msg += f"üîç **{result['name']}**\n"

        if result["success"]:
            result_msg += f"‚úÖ Eri≈üim: Ba≈üarƒ±lƒ±\n"
            result_msg += f"üîó Toplam link: {result['links_found']}\n"

            if result.get("first_check"):
                result_msg += f"üÜï ƒ∞lk kontrol - sƒ±ralama kaydedildi\n"
            else:
                if result.get("ranking_changed"):
                    result_msg += f"üö® **SIRALAMA DEƒûƒ∞≈ûTƒ∞!**\n"
                    result_msg += f"üìä {result.get('change_summary', 'Sƒ±ralama g√ºncellendi')}\n"
                    changes_found += 1
                else:
                    result_msg += f"‚úÖ {result.get('change_summary', 'Sƒ±ralama aynƒ±')}\n"

            # ƒ∞lk 3 linki g√∂ster
            links = result.get("links", [])[:3]
            if links:
                result_msg += f"üìã ƒ∞lk 3 link:\n"
                for link in links:
                    result_msg += f"‚Ä¢ {link['position']}. {link['text'][:30]}...\n"

        else:
            result_msg += f"‚ùå Eri≈üim: Ba≈üarƒ±sƒ±z\n"
            result_msg += f"‚ö†Ô∏è Hata: {result.get('error', 'Bilinmiyor')[:100]}...\n"

        result_msg += "\n"

    # √ñzet
    result_msg += f"üéØ **√ñzet:**\n"
    if changes_found > 0:
        result_msg += f"üö® **SIRALAMA DEƒûƒ∞≈ûTƒ∞!**\n"
        result_msg += f"üîÑ Kopilbey Sponsorlar sayfasƒ±nda link sƒ±ralamasƒ± g√ºncellendi!\n"
    else:
        result_msg += f"‚úÖ Kopilbey Sponsorlar sayfasƒ±nda deƒüi≈üiklik yok\n"

    send_telegram_message(result_msg)

    print(f"‚úÖ Kontrol tamamlandƒ± - {successful}/{len(results)} ba≈üarƒ±lƒ±")

if __name__ == "__main__":
    main()
