#!/usr/bin/env python3
"""
GitHub Actions iÃ§in Tek Kontrol Scripti
"""

import urllib.request
import urllib.parse
import json
import re
import random
import hashlib
import time
import os
from datetime import datetime
import requests
import ssl
from bs4 import BeautifulSoup
import cloudscraper
from fake_useragent import UserAgent

# Selenium imports (GitHub Actions iÃ§in)
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager

# Environment variables'dan oku
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "")
TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID", "")

# Global geÃ§miÅŸ (GitHub Actions'ta persist etmez ama basit iÃ§in OK)
page_history = {}

# Ãœcretsiz proxy listesi (gÃ¼ncellenebilir)
PROXY_LIST = [
    {'http': 'http://51.159.115.233:3128', 'https': 'http://51.159.115.233:3128'},
    {'http': 'http://20.205.61.143:3128', 'https': 'http://20.205.61.143:3128'},
    {'http': 'http://103.151.177.106:8080', 'https': 'http://103.151.177.106:8080'},
    {'http': 'http://185.82.99.181:9091', 'https': 'http://185.82.99.181:9091'},
    {'http': 'http://190.97.226.236:999', 'https': 'http://190.97.226.236:999'},
    {'http': 'http://181.78.22.52:999', 'https': 'http://181.78.22.52:999'},
    {'http': 'http://45.70.236.194:999', 'https': 'http://45.70.236.194:999'},
    {'http': 'http://200.105.215.18:33630', 'https': 'http://200.105.215.18:33630'},
    {'http': 'http://190.103.177.131:80', 'https': 'http://190.103.177.131:80'},
    {'http': 'http://181.78.22.150:999', 'https': 'http://181.78.22.150:999'}
]

HEYLINKS = [
    {
        "url": "https://heylink.me/Kopilbeysponsorlar/",
        "name": "Kopilbey Sponsorlar"
    }
]

def send_telegram_message(message):
    """Telegram mesajÄ± gÃ¶nder"""
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID:
        print("âŒ Telegram config eksik")
        return

    try:
        url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
        data = {
            'chat_id': TELEGRAM_CHAT_ID,
            'text': message,
            'parse_mode': 'Markdown',
            'disable_web_page_preview': True
        }

        data = urllib.parse.urlencode(data).encode('utf-8')
        req = urllib.request.Request(url, data=data, method='POST')
        with urllib.request.urlopen(req, timeout=10) as response:
            print("âœ… Telegram mesajÄ± gÃ¶nderildi")
    except Exception as e:
        print(f"âŒ Telegram hatasÄ±: {e}")

def scrape_heylink(url, name):
    """SayfayÄ± scrape et ve link sÄ±ralamasÄ± deÄŸiÅŸikliklerini tespit et"""
    try:
        # Fake user agent oluÅŸturucu
        ua = UserAgent()

        # Heylink iÃ§in Ã§ok uzun delay (Cloudflare bypass iÃ§in)
        if 'heylink' in url.lower():
            delay = random.uniform(20, 35)
        else:
            delay = random.uniform(5, 10)

        print(f"â³ {name}: {delay:.1f}s bekleniyor...")
        time.sleep(delay)

        # Cloudscraper ile gÃ¼Ã§lÃ¼ Cloudflare bypass
        print(f"ğŸ”¥ {name}: Cloudscraper ile Cloudflare bypass baÅŸlatÄ±lÄ±yor...")
        try:
            # cloudscraper ile Cloudflare bypass
            scraper = cloudscraper.create_scraper(
                browser={
                    'browser': 'chrome',
                    'platform': 'windows',
                    'desktop': True
                }
            )
            response = scraper.get(url, timeout=60)

            if response.status_code == 200:
                html = response.text
                print(f"âœ… {name}: Cloudscraper baÅŸarÄ±lÄ±!")
            else:
                raise Exception(f"HTTP {response.status_code}")

        except Exception as cf_error:
            print(f"âš ï¸ {name}: Cloudscraper baÅŸarÄ±sÄ±z ({cf_error}), Selenium deneniyor...")
            try:
                # Selenium fallback
                chrome_options = Options()
                chrome_options.add_argument('--headless')
                chrome_options.add_argument('--no-sandbox')
                chrome_options.add_argument('--disable-dev-shm-usage')
                chrome_options.add_argument('--disable-gpu')
                chrome_options.add_argument('--window-size=1920,1080')
                chrome_options.add_argument('--disable-blink-features=AutomationControlled')
                chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
                chrome_options.add_experimental_option('useAutomationExtension', False)
                chrome_options.add_argument(f'--user-agent={ua.random}')

                driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)

                # Webdriver detection bypass
                driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")

                driver.get(url)
                time.sleep(15)

                html = driver.page_source
                driver.quit()

                print(f"âœ… {name}: Selenium baÅŸarÄ±lÄ±!")

            except Exception as selenium_error:
                print(f"âŒ {name}: TÃ¼m yÃ¶ntemler baÅŸarÄ±sÄ±z - {selenium_error}")
                raise Exception("TÃ¼m bypass yÃ¶ntemleri baÅŸarÄ±sÄ±z")
        # Debug: Save HTML to file for inspection
        with open("heylink_content.html", "w", encoding="utf-8") as f:
            f.write(html)
        print("heylink_content.html dosyasÄ±na kaydedildi.")

        def parse_links_from_html(page_html):
            """Heylink sayfasÄ±ndaki sponsor linklerini Ã§Ä±kar."""
            parsed_links = []
            soup = BeautifulSoup(page_html, "html.parser")
            cards = soup.select("div.preview-link-item__component a.preview-link-wrapper")
            for idx, card in enumerate(cards, start=1):
                href = card.get("href", "").strip()
                if not href or href.startswith(("javascript:", "mailto:", "#", "tel:")):
                    continue
                name_el = card.select_one(".link-info .name")
                text = name_el.get_text(strip=True) if name_el else card.get_text(strip=True)
                if not text:
                    text = href
                parsed_links.append(
                    {
                        "position": idx,
                        "text": text[:120],
                        "href": href,
                    }
                )
            return parsed_links

        # Linkleri Ã§Ä±kar (BeautifulSoup ile Ã¶ncelikli, regex yedekli)
        links = parse_links_from_html(html)
        link_count = len(links)

        if not links:
            try:
                # TÃ¼m link tag'larÄ±nÄ± say (yedek)
                link_count = len(re.findall(r'<a[^>]*href[^>]*>.*?</a>', html, re.IGNORECASE | re.DOTALL))
                link_matches = re.findall(r'<a[^>]*href=["\']([^"\']+)["\'][^>]*>([^<]*)</a>', html, re.IGNORECASE | re.DOTALL)

                for i, (href, text) in enumerate(link_matches[:5]):  # Sadece ilk 5
                    if href and not href.startswith(('javascript:', 'mailto:', '#', 'tel:')):
                        clean_text = text.strip()[:120] if text.strip() else href[:120]
                        links.append({
                            'position': i + 1,
                            'text': clean_text,
                            'href': href
                        })

                if not links:
                    for i in range(min(3, link_count)):  # En fazla 3 boÅŸ link
                        links.append({
                            'position': i + 1,
                            'text': f'Link {i+1}',
                            'href': f'#link{i+1}'
                        })
            except Exception as parse_error:
                print(f"âš ï¸ Link parsing hatasÄ±: {parse_error}")
                link_count = len(links)


        # Link listesinin hash'i
        links_hash = hashlib.md5(str(links).encode('utf-8')).hexdigest()

        result = {
            "success": True,
            "name": name,
            "url": url,
            "links_found": len(links),
            "links": links[:10],
            "links_hash": links_hash,
            "timestamp": datetime.now().isoformat()
        }

        # GeÃ§miÅŸ ile karÅŸÄ±laÅŸtÄ±r
        url_key = url
        if url_key in page_history:
            prev_data = page_history[url_key]
            prev_hash = prev_data.get('links_hash', '')

            if links_hash != prev_hash:
                result["ranking_changed"] = True
                result["change_summary"] = "ğŸ”„ Link sÄ±ralamasÄ± deÄŸiÅŸti"
            else:
                result["ranking_changed"] = False
                result["change_summary"] = "âœ… Link sÄ±ralamasÄ± aynÄ±"
        else:
            result["first_check"] = True
            result["change_summary"] = "ğŸ†• Ä°lk kontrol - referans kaydedildi"

        # GeÃ§miÅŸi gÃ¼ncelle
        page_history[url_key] = {
            'links': links,
            'links_hash': links_hash,
            'timestamp': result['timestamp']
        }

        return result

    except Exception as e:
        print(f"âŒ {name}: Hata - {str(e)}")
        return {
            "success": False,
            "name": name,
            "url": url,
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

def main():
    print("ğŸ¤– GitHub Actions - Heylink Tracker")
    print("ğŸ“Š Tek kontrol baÅŸlatÄ±lÄ±yor...")
    print("=" * 50)

    # BaÅŸlangÄ±Ã§ bildirimi
    start_msg = "ğŸ¤– **GitHub Actions - Kontrol BaÅŸlÄ±yor**\n\n"
    start_msg += f"ğŸ“… {datetime.now().strftime('%H:%M:%S')}\n"
    start_msg += f"ğŸ¯ **Kopilbey Sponsorlar** sayfasÄ± kontrol ediliyor\n\n"
    start_msg += f"ğŸ”„ Her 15 dakikada bir link sÄ±ralamasÄ± kontrol edilecek"

    send_telegram_message(start_msg)

    results = []
    for heylink in HEYLINKS:
        result = scrape_heylink(heylink["url"], heylink["name"])
        results.append(result)

    # DetaylÄ± rapor
    result_msg = f"ğŸ¤– **GitHub Actions - Kontrol TamamlandÄ±**\n\n"
    result_msg += f"ğŸ“… {datetime.now().strftime('%H:%M:%S')}\n\n"

    successful = sum(1 for r in results if r["success"])
    errors = len(results) - successful
    changes_found = 0

    result_msg += f"ğŸ“Š **Genel Durum:**\n"
    result_msg += f"âœ… {successful} baÅŸarÄ±lÄ±\n"
    if errors > 0:
        result_msg += f"âŒ {errors} hata\n"
    result_msg += "\n"

    for result in results:
        result_msg += f"ğŸ” **{result['name']}**\n"

        if result["success"]:
            result_msg += f"âœ… EriÅŸim: BaÅŸarÄ±lÄ±\n"
            result_msg += f"ğŸ”— Toplam link: {result['links_found']}\n"

            if result.get("first_check"):
                result_msg += f"ğŸ†• Ä°lk kontrol - sÄ±ralama kaydedildi\n"
            else:
                if result.get("ranking_changed"):
                    result_msg += f"ğŸš¨ **SIRALAMA DEÄÄ°ÅTÄ°!**\n"
                    result_msg += f"ğŸ“Š {result.get('change_summary', 'SÄ±ralama gÃ¼ncellendi')}\n"
                    changes_found += 1
                else:
                    result_msg += f"âœ… {result.get('change_summary', 'SÄ±ralama aynÄ±')}\n"

            # Ä°lk 3 linki gÃ¶ster
            links = result.get("links", [])[:3]
            if links:
                result_msg += f"ğŸ“‹ Ä°lk 3 link:\n"
                for link in links:
                    result_msg += f"â€¢ {link['position']}. {link['text'][:30]}...\n"

        else:
            result_msg += f"âŒ EriÅŸim: BaÅŸarÄ±sÄ±z\n"
            result_msg += f"âš ï¸ Hata: {result.get('error', 'Bilinmiyor')[:100]}...\n"

        result_msg += "\n"

    # Ã–zet
    result_msg += f"ğŸ¯ **Ã–zet:**\n"
    if changes_found > 0:
        result_msg += f"ğŸš¨ **SIRALAMA DEÄÄ°ÅTÄ°!**\n"
        result_msg += f"ğŸ”„ Kopilbey Sponsorlar sayfasÄ±nda link sÄ±ralamasÄ± gÃ¼ncellendi!\n"
    else:
        result_msg += f"âœ… Kopilbey Sponsorlar sayfasÄ±nda deÄŸiÅŸiklik yok\n"

    send_telegram_message(result_msg)

    print(f"âœ… Kontrol tamamlandÄ± - {successful}/{len(results)} baÅŸarÄ±lÄ±")

if __name__ == "__main__":
    main()
